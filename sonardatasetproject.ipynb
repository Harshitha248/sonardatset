{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "behavioral-cameroon",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "raw",
   "id": "unavailable-litigation",
   "metadata": {},
   "source": [
    "in this learning and statistics machine , feature selection is the process of selecting a subset of features to be used in model construction. Feature selection techniques were used for three reasons as follow\n",
    "1. to simplify the models.\n",
    "2. to reduce training time\n",
    "3. to enhanced generalization\n",
    "The feature selection has been widely used to reduce the data dimensionality.Data reduction improve the classification performance, the approximationfunction,and pattern recognition system interms of speed, accuracy and simplicity. A strategy to reduce the number of features in local search are sequental search algorithms\n",
    "Artificial Neural Networks is one of the artificial intelligent techniques commmonly used, because of its ability to capture and represent complex input and output relationships amoong data.Neural Network are composed of simple elements operating in parallel. these elements are inspired by biological nervous systems.as in nature,the network function is mainly determined by connections between elements. it is usedd in various fields of application including pattern recognition, identification, speech, vision, classification and control systems.The advantage of fuzzy interference system os that it can dela with linguistic expressions and advantage of the Neural network is that it can be trained and so can self_learn and self-improve.jang in 1933 took both advantages ,combining the 2 techniques and proposed adaptive neuro-Fuzzy inference systems(AFINS). The idea behind neural network and fuzzy interference combination is to design a system that uses a fuzzy system to represent the knowledge in an interpretable manner and the learning ability derived from a neural network that can adjust the membership function parameters and linguistic rules directly  from data in order to enhance the system performance \n",
    "K-Nearest neighbor(KNN)  classification is one of the most fundamental and simple classiication methods,although it can also be used  for estimation and prediction. it was developed from the need to perform the discriminant analysis when reliable parametric estimates of probability densities are unknown or difficult to dtermine. it provides goood performance for optimal vales of k"
   ]
  },
  {
   "cell_type": "raw",
   "id": "portable-interpretation",
   "metadata": {},
   "source": [
    "# The file \"sonar. mines\" contains 111 patterns obtained by bouncing sonar signals off a metal cylinder at various angles and under various conditions. The file sonar.rocks contains 97 patterns obtained from rocks under similar conditions.The transmittted sonar signal is a frequency-modulated chirp, rising in frequency. The dataset contains the signals obtained from variety of different aspect angles,spanning 90 degrees for the cylinder and 180 degreed for rock.\n",
    "\n",
    "each pattern is a set of 60 numbers in the range 0.0 to 1.0.each number represents the energy within a particular frequency band, integrated over a certain period of time. The integration apperture for higher frequencies occur later in time,since these frquencies are transmitted later during the chirp.The label associated with each record contains the letter \"R\".if the object is a rock and \"M\" if it is a mine(metal cylinder). The numbers in the labels are in the increasing order of the aspect angle, but they do not encode the aangles directly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-north",
   "metadata": {},
   "source": [
    "# objective\n",
    "The task is to train a network to discriminate between sonar signals bounced off a metal cylinder and those bounded off a roughly cylinder rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "expressed-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fabulous-distinction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V52</th>\n",
       "      <th>V53</th>\n",
       "      <th>V54</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      V1      V2      V3      V4      V5      V6      V7      V8  \\\n",
       "0           1  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601   \n",
       "1           2  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481   \n",
       "2           3  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771   \n",
       "3           4  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276   \n",
       "4           5  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467   \n",
       "\n",
       "       V9  ...     V52     V53     V54     V55     V56     V57     V58  \\\n",
       "0  0.3109  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.3337  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.5598  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.0598  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.3564  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "      V59     V60  Class  \n",
       "0  0.0090  0.0032      R  \n",
       "1  0.0052  0.0044      R  \n",
       "2  0.0095  0.0078      R  \n",
       "3  0.0040  0.0117      R  \n",
       "4  0.0107  0.0094      R  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "dat = pd.read_csv(\"Sonar.csv\")\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "yellow-trail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 62)\n"
     ]
    }
   ],
   "source": [
    "# dat.head()\n",
    "print(dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "collected-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 'Class' column to 'category' data type\n",
    "X = dat.drop('Class', 1)\n",
    "dat['Class'] = dat['Class'].astype('category')\n",
    "y = dat['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abandoned-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train / test data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "therapeutic-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the logistic regression model\n",
    "logReg = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "expressed-cemetery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35  0]\n",
      " [13 15]]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on test data set\n",
    "y_pred = logReg.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "viral-camcorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7936507936507936\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "living-nursery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the naive bayes model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "growing-judgment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9523809523809523"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "british-publicity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33  2]\n",
      " [ 1 27]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = nb.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "municipal-lounge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "million-conditions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support vector machine model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "numerous-weather",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True, random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(random_state=42, probability=True)\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "typical-frank",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sixth-hampton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35  0]\n",
      " [ 0 28]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = svc.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "medieval-interaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "lovely-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "unlike-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "greater-conversion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "caroline-soundtrack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35  0]\n",
      " [ 0 28]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "surrounded-paragraph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "injured-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a knn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sonic-latest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knc = KNeighborsClassifier()\n",
    "knc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dynamic-resolution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "coordinate-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eligible-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "complete-camel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "mysterious-tactics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9841269841269841"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
